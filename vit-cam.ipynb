{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30918,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import ViTForImageClassification, ViTFeatureExtractor\nfrom PIL import Image\nimport pandas as pd\nimport os","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-22T15:18:46.489592Z","iopub.execute_input":"2025-03-22T15:18:46.489981Z","iopub.status.idle":"2025-03-22T15:18:46.495251Z","shell.execute_reply.started":"2025-03-22T15:18:46.489950Z","shell.execute_reply":"2025-03-22T15:18:46.494088Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"from transformers import ViTForImageClassification, ViTFeatureExtractor\n\n#Load ImageNet pre-trained ViT\nmodel_name = 'google/vit-base-patch16-224-in21k' #Model version\nmodel = ViTForImageClassification.from_pretrained(model_name, num_labels = 8) #CheXray-8\n\n# Feature extractor for preprocessing images\nfeature_extractor = ViTFeatureExtractor.from_pretrained(model_name)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-22T15:18:49.981325Z","iopub.execute_input":"2025-03-22T15:18:49.981696Z","iopub.status.idle":"2025-03-22T15:18:52.986371Z","shell.execute_reply.started":"2025-03-22T15:18:49.981671Z","shell.execute_reply":"2025-03-22T15:18:52.984833Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/502 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cb1faba3841e42ddb6848887d135085e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/346M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4fb7aae835014dc29b3e9ff5ca69cb3b"}},"metadata":{}},{"name":"stderr","text":"Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/160 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a56ca98c7fc4c3fbcd8c5574b289d51"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/models/vit/feature_extraction_vit.py:28: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"class CheXrayDataset(Dataset):\n    def __init__(self, img_dir, labels_csv, feature_extractor, transform=None):\n        self.img_dir = img_dir\n        self.labels = pd.read_csv(labels_csv)\n        self.feature_extractor = feature_extractor\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        row = self.labels.iloc[idx]\n        img_path = os.path.join(self.img_dir, row['Image Index'])\n        image = Image.open(img_path).convert('RGB')\n\n        # Apply preprocessing\n        inputs = self.feature_extractor(images=image, return_tensors=\"pt\")\n\n        # Convert label row to tensor\n        label = torch.tensor(row[1:].values.astype(float))  # assuming labels are from column 1 onwards (multi-label)\n\n        return {\n            'pixel_values': inputs['pixel_values'].squeeze(),  # remove batch dim\n            'labels': label\n        }\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_name = 'google/vit-base-patch16-224-in21k'\nfeature_extractor = ViTFeatureExtractor.from_pretrained(model_name)\n\nmodel = ViTForImageClassification.from_pretrained(\n    model_name,\n    num_labels=8,       # 8 diseases\n    problem_type=\"multi_label_classification\"  # Important for CheXray8\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dataset = CheXrayDataset(\n    img_dir='/path/to/images',\n    labels_csv='/path/to/labels.csv',\n    feature_extractor=feature_extractor\n)\n\ndataloader = DataLoader(dataset, batch_size=16, shuffle=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\noptimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\ncriterion = torch.nn.BCEWithLogitsLoss()  # for multi-label classification\n\nepochs = 100  # adjust as needed\n\nfor epoch in range(epochs):\n    model.train()\n    total_loss = 0\n\n    for batch in dataloader:\n        inputs = batch['pixel_values'].to(device)\n        labels = batch['labels'].to(device)\n\n        outputs = model(pixel_values=inputs)\n        logits = outputs.logits\n\n        loss = criterion(logits, labels)\n        total_loss += loss.item()\n\n        loss.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n    print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss / len(dataloader)}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}
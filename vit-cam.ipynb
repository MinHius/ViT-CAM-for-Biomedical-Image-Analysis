{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import ViTForImageClassification, ViTFeatureExtractor\nfrom PIL import Image\nimport pandas as pd\nimport os","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-22T15:18:46.489592Z","iopub.execute_input":"2025-03-22T15:18:46.489981Z","iopub.status.idle":"2025-03-22T15:18:46.495251Z","shell.execute_reply.started":"2025-03-22T15:18:46.489950Z","shell.execute_reply":"2025-03-22T15:18:46.494088Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"from transformers import ViTForImageClassification, ViTFeatureExtractor\n\n#Load ImageNet pre-trained ViT\nmodel_name = 'google/vit-base-patch16-224-in21k' #Model version\nmodel = ViTForImageClassification.from_pretrained(model_name, num_labels = 8) #CheXray-8\n\n# Feature extractor for preprocessing images\nfeature_extractor = ViTFeatureExtractor.from_pretrained(model_name)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-22T15:18:49.981325Z","iopub.execute_input":"2025-03-22T15:18:49.981696Z","iopub.status.idle":"2025-03-22T15:18:52.986371Z","shell.execute_reply.started":"2025-03-22T15:18:49.981671Z","shell.execute_reply":"2025-03-22T15:18:52.984833Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/502 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cb1faba3841e42ddb6848887d135085e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/346M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4fb7aae835014dc29b3e9ff5ca69cb3b"}},"metadata":{}},{"name":"stderr","text":"Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/160 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a56ca98c7fc4c3fbcd8c5574b289d51"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/models/vit/feature_extraction_vit.py:28: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"model_name = 'google/vit-base-patch16-224-in21k'\nfeature_extractor = ViTFeatureExtractor.from_pretrained(model_name)\n\nmodel = ViTForImageClassification.from_pretrained(\n    model_name,\n    num_labels=8,       # 8 diseases\n    problem_type=\"multi_label_classification\"  # Important for CheXray8\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# DATASET.","metadata":{}},{"cell_type":"code","source":"import kagglehub\n\n# Download latest version\npath = kagglehub.dataset_download(\"minhnhat232/dataset-covid-bacterial-viral-normal-emphysema\")\n\nprint(\"Path to dataset files:\", path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-22T15:42:22.408234Z","iopub.execute_input":"2025-03-22T15:42:22.410377Z","iopub.status.idle":"2025-03-22T15:45:32.534798Z","shell.execute_reply.started":"2025-03-22T15:42:22.410303Z","shell.execute_reply":"2025-03-22T15:45:32.533433Z"}},"outputs":[{"name":"stdout","text":"Mounting files to /kaggle/input/dataset-covid-bacterial-viral-normal-emphysema...\nPath to dataset files: /kaggle/input/dataset-covid-bacterial-viral-normal-emphysema\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"#Read dataset.","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# TRAIN.","metadata":{}},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\noptimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\ncriterion = torch.nn.BCEWithLogitsLoss()  # for multi-label classification\n\nepochs = 1  # adjust as needed\n\nfor epoch in range(epochs):\n    model.train()\n    total_loss = 0\n\n    for batch in dataloader:\n        inputs = batch['pixel_values'].to(device)\n        labels = batch['labels'].to(device)\n\n        outputs = model(pixel_values=inputs)\n        logits = outputs.logits\n\n        loss = criterion(logits, labels)\n        total_loss += loss.item()\n\n        loss.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n    print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss / len(dataloader)}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}